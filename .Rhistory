cbind(get_entries(splits[[1]][x], name), get_categories(splits[[1]][length(splits[[1]])]))
}
names[999]
table = get_table(names[999])
get_row = function(name){
t = GET(get_url(name))
this.raw.content <- rawToChar(t$content)
this.content <- fromJSON(this.raw.content)
df = as.data.frame(this.content[[1]])
text = df[length(df)][[1]]
text = gsub("<[^>]+>", "",text)
text = str_replace_all(text, "'", "")
text = str_replace_all(text, "[\\[\\]]", "")
text = delete_if_it_exists(text, "DISPLAYTITLE", fixed("\n"))
text = delete_if_it_exists(text, "Youmay|", fixed("\n"))
text = delete_if_it_exists(text, "Youmay|", fixed("\n"))
splits = str_split(text, "\\}\\}")
x = which(str_locate(splits[[1]], fixed("|")) != "")[1]
cbind(get_entries(splits[[1]][x], name), get_categories(splits[[1]][length(splits[[1]])]))
}
table = get_table(names[1000:1050])
table = get_table(names[1050:1100])
table = get_table(names[1100:1188])
View(table)
table = get_table(names[74])
names[74]
table = get_table(names[1:100])
table = get_table(names[1:73])
table = get_table(names[75:150])
table = get_table(names[150:200])
table = get_table(names[200:300])
library(httr)
library(jsonlite)
library(stringr)
library(data.table)
## --------- functions for scraping ---------------------
#exclude
#Bird_Woman (74) (redirection to Gunter's page)
#Forest_inhabitant (418) (group of characters)
#Son_of_Rap_Bear_(character) (999) (stub)
get_names = function(){
url = "https://adventuretime.fandom.com/wiki/Category:Characters"
from = "?from="
list = get_names_for_url(url)
for(i in 1:6){
print(list[length(list)])
next_url = paste(c(url, from, list[length(list)]), collapse = "")
print(next_url)
l = get_names_for_url(next_url)
print(length(l))
k = c(list, l)
list = k
}
list
}
get_names_for_url = function(url){
chars = GET(url)
raw = rawToChar(chars$content)
chars = str_sub(raw, str_locate(raw, "All items")[1], str_length(raw))
s = str_split(chars, fixed("<a href=\"/wiki/"))
chars = s[[1]][c(T,F)]
n = lapply(chars[-1], subname, pattern = "\"", nr = 1)
n = delete_betises(n, ":")
n = delete_betises(n, fixed("Local_Sitemap"))
}
delete_betises = function(n, pat){
x = which(str_locate(n, pat) != "")
if(length(x) > 0) n = n[-x]
else n
}
## now the functions for the data table
get_table = function(names){
#urls = lapply(names, get_url)
rbindlist(lapply(names, get_row), fill = T)
}
get_url = function(name){
paste(c("https://adventuretime.fandom.com/api.php?action=query&prop=revisions&titles=",
name, "&rvprop=content&format=json"), collapse = "")
}
get_row = function(name){
nap(1)
t = GET(get_url(name))
this.raw.content <- rawToChar(t$content)
this.content <- fromJSON(this.raw.content)
df = as.data.frame(this.content[[1]])
text = df[length(df)][[1]]
text = gsub("<[^>]+>", "",text)
text = str_replace_all(text, "'", "")
text = str_replace_all(text, "[\\[\\]]", "")
text = delete_if_it_exists(text, "DISPLAYTITLE", fixed("\n"))
text = delete_if_it_exists(text, "Youmay|", fixed("\n"))
text = delete_if_it_exists(text, "Youmay|", fixed("\n"))
splits = str_split(text, "\\}\\}")
x = which(str_locate(splits[[1]], fixed("|")) != "")[1]
cbind(get_entries(splits[[1]][x], name), get_categories(splits[[1]][length(splits[[1]])]))
}
get_entries = function(cols, c_name){
cols = str_replace_all(cols, "[ \t\r\n]", "")
data = str_split(cols, fixed("|"))
x = which(str_locate(data[[1]], fixed("=")) != "")
data[[1]][x[x < length(data[[1]]) + 1]]
list = lapply(data[[1]][x[x < length(data[[1]]) + 1]], get_df)
n = str_replace_all(c_name, fixed("_"), " ")
#if("name" %in% names(list) == FALSE || list$name != n)
#  list[[1]]$name = n
as.data.frame(list)
}
get_categories = function(cats){
splits = str_split(cats, "Category:")
df = data.frame(categories = paste(splits[[1]][2:length(splits[[1]])],collapse=", "))
}
get_df = function(x_eq_y){
splits = str_split(x_eq_y, "=")
df = data.frame(splits[[1]][2])
names(df) <- splits[[1]][1]
if(names(df) == "species" && str_sub(df$species, str_length(df$species), str_length(df$species)) == "s")
df$species = str_sub(df$species, 1, str_length(df$species) -1)
df
}
delete_if_it_exists = function(string, pattern, splitter){
if(grepl(pattern, string, fixed = T)){
start = str_locate(string, splitter)[1]
string = str_sub(string, start + 1, str_length(string))
}
string
}
nap = function(x)
{
p1 = proc.time()
Sys.sleep(x)
proc.time() - p1 # The cpu usage should be negligible
}
#subname = function(name, pattern, nr){
#  splits = str_split(name, pattern)
#  splits[[1]][nr]
#}
table = get_table(names[1:3])
?sleep
?Sys.sleep
c = c(74, 418, 999)
names = names[-c]
table = get_table(names[1:3])
names[999]
names[998]
names[997]
names[996]
names[995]
names[994]
names[993]
names[992]
library(httr)
library(jsonlite)
library(stringr)
library(data.table)
## --------- functions for scraping ---------------------
get_names = function(){
url = "https://adventuretime.fandom.com/wiki/Category:Characters"
from = "?from="
list = get_names_for_url(url)
for(i in 1:6){
print(list[length(list)])
next_url = paste(c(url, from, list[length(list)]), collapse = "")
print(next_url)
l = get_names_for_url(next_url)
print(length(l))
k = c(list, l)
list = k
}
list
}
get_names_for_url = function(url){
chars = GET(url)
raw = rawToChar(chars$content)
chars = str_sub(raw, str_locate(raw, "All items")[1], str_length(raw))
s = str_split(chars, fixed("<a href=\"/wiki/"))
chars = s[[1]][c(T,F)]
n = lapply(chars[-1], subname, pattern = "\"", nr = 1)
n = delete_betises(n, ":")
n = delete_betises(n, fixed("Local_Sitemap"))
}
delete_betises = function(n, pat){
x = which(str_locate(n, pat) != "")
if(length(x) > 0) n = n[-x]
else n
}
## now the functions for the data table
get_table = function(names){
#exclude unwanted pages:
#Bird_Woman (74) (redirection to Gunter's page)
#Forest_inhabitant (418) (group of characters)
#Son_of_Rap_Bear_(character) (999) (stub)
c = c(74, 418, 999)
names = names[-c]
rbindlist(lapply(names, get_row), fill = T)
}
get_url = function(name){
paste(c("https://adventuretime.fandom.com/api.php?action=query&prop=revisions&titles=",
name, "&rvprop=content&format=json"), collapse = "")
}
get_row = function(name){
nap(0.5)
t = GET(get_url(name))
this.raw.content <- rawToChar(t$content)
this.content <- fromJSON(this.raw.content)
df = as.data.frame(this.content[[1]])
text = df[length(df)][[1]]
text = gsub("<[^>]+>", "",text)
text = str_replace_all(text, "'", "")
text = str_replace_all(text, "[\\[\\]]", "")
text = delete_if_it_exists(text, "DISPLAYTITLE", fixed("\n"))
text = delete_if_it_exists(text, "Youmay|", fixed("\n"))
text = delete_if_it_exists(text, "Youmay|", fixed("\n"))
splits = str_split(text, "\\}\\}")
x = which(str_locate(splits[[1]], fixed("|")) != "")[1]
cbind(get_entries(splits[[1]][x], name), get_categories(splits[[1]][length(splits[[1]])]))
}
get_entries = function(cols, c_name){
cols = str_replace_all(cols, "[ \t\r\n]", "")
data = str_split(cols, fixed("|"))
x = which(str_locate(data[[1]], fixed("=")) != "")
data[[1]][x[x < length(data[[1]]) + 1]]
list = lapply(data[[1]][x[x < length(data[[1]]) + 1]], get_df)
n = str_replace_all(c_name, fixed("_"), " ")
#if("name" %in% names(list) == FALSE || list$name != n)
#  list[[1]]$name = n
as.data.frame(list)
}
get_categories = function(cats){
splits = str_split(cats, "Category:")
df = data.frame(categories = paste(splits[[1]][2:length(splits[[1]])],collapse=", "))
}
get_df = function(x_eq_y){
splits = str_split(x_eq_y, "=")
df = data.frame(splits[[1]][2])
names(df) <- splits[[1]][1]
if(names(df) == "species" && str_sub(df$species, str_length(df$species), str_length(df$species)) == "s")
df$species = str_sub(df$species, 1, str_length(df$species) -1)
df
}
delete_if_it_exists = function(string, pattern, splitter){
if(grepl(pattern, string, fixed = T)){
start = str_locate(string, splitter)[1]
string = str_sub(string, start + 1, str_length(string))
}
string
}
nap = function(x)
{
p1 = proc.time()
Sys.sleep(x)
proc.time() - p1 # The cpu usage should be negligible
}
#subname = function(name, pattern, nr){
#  splits = str_split(name, pattern)
#  splits[[1]][nr]
#}
names <- readRDS("C:/Users/Lilli/git/adventuretime/characterNames.rds")
names <- readRDS("characterNames.rds")
View(table)
create_and_save_table(){
table = get_table(read_names())
write.csv(table, file = "adventuretime.csv")
}
read_names = function(){
names <- readRDS("characterNames.rds")
}
create_and_save_table = function(){
table = get_table(read_names())
write.csv(table, file = "adventuretime.csv")
}
read_names = function(){
names <- readRDS("characterNames.rds")
}
create_and_save_table()
library(readr)
adventuretime <- read_csv("adventuretime.csv")
View(adventuretime)
library(readr)
adventuretime <- read_csv("adventuretime.csv", header = TRUE, encoding = "UTF-8")
read.csv("adventuretime.csv", header = TRUE, encoding = "UTF-8")
table = read.csv("adventuretime.csv", header = TRUE, encoding = "UTF-8")
View(table)
summary(table$sex)
my.read.csv = function(file.name) {
read.csv(file.name, header = TRUE, encoding = "UTF-8")
}
table = my.read.csv("adventuretime.csv")
View(table)
which(table$name == "{{PAGENAME")
my.read.csv = function(file.name) {
read.csv(file.name, header = TRUE, encoding = "UTF-8", stringsAsFactors = FALSE)
}
table = my.read.csv("adventuretime.csv")
names <- readRDS("C:/Users/Lilli/git/adventuretime/characterNames.rds")
which(match(table$name, NA) == 1)
c1 = which(match(table$name, NA) == 1)
c2 = which(table$name == "{{PAGENAME")
c(c1,c2)
to_ref = sort(c(c1,c2))
to_ref
table$name[9]
table$name[13]
table$name[c(9,13)] = c("hallo", "hallo2")
table$name[c(9,13)]
table = my.read.csv("adventuretime.csv")
my.read.csv = function(file.name) {
read.csv(file.name, header = TRUE, encoding = "UTF-8", stringsAsFactors = FALSE)
}
table = my.read.csv("adventuretime.csv")
refactor_names = function(){
names <- readRDS("characterNames.rds")
#exclude unwanted pages:
#Bird_Woman (74) (redirection to Gunter's page)
#Forest_inhabitant (418) (group of characters)
#Son_of_Rap_Bear_(character) (999) (stub)
c = c(74, 418, 999)
names = names[-c]
c1 = which(match(table$name, NA) == 1)
c2 = which(table$name == "{{PAGENAME")
to_ref = sort(c(c1,c2))
newNames = names[to_ref]
table$name[to_ref] = newNames
}
refactor_names()
table$name[9]
table$name[13]
newNames = names[to_ref]
table$name[to_ref] = newNames
table$name[13]
table$name[12]
View(table)
grepl("Princess", table$categories, fixed = T)
which(grepl("Princess", table$categories, fixed = T))
getRowsWithSpecialValue = function(table, colname, value, perfectMatch){
if (missing(perfectMatch)) {
perfectMatch = FALSE
}
if(perfectMatch){
return(table[which(table[colname] == value),])
}
else
return(table[which(grepl(value, table$categories, fixed = T))])
}
getRowsWithSpecialValue(table, "categories", "Princess")
which(grepl("Princess", table$categories, fixed = T))
table[which(grepl("Princess", table$categories, fixed = T))]
table$categories[which(grepl("Princess", table$categories, fixed = T))]
table[1]
getRowsWithSpecialValue = function(table, colname, value, perfectMatch){
if (missing(perfectMatch)) {
perfectMatch = FALSE
}
if(perfectMatch){
return(table[which(table[colname] == value),])
}
else
return(table[which(grepl(value, table$categories, fixed = T)),])
}
getRowsWithSpecialValue(table, "categories", "Princess")
princesses = getRowsWithSpecialValue(table, "categories", "Princess")
View(princesses)
getRowsWithSpecialValue = function(table, colname, value, perfectMatch, dontInvertQuery){
if (missing(perfectMatch)) {
perfectMatch = FALSE
}
if (missing(dontInvertQuery)) {
dontInvertQuery = TRUE
}
if(perfectMatch){
return(table[which(table[colname] == value),])
}
else
return(table[which(grepl(value, table$categories, fixed = T) == dontInvertQuery),])
}
princesses = getRowsWithSpecialValue(table, "categories", "Princess")
noprincesses = getRowsWithSpecialValue(table, "categories", "Princess", dontInvertQuery = FALSE)
female = getRowsWithSpecialValue(table, "sex", "Female", perfectMatch = TRUE)
femaleAndPrincess = getRowsWithSpecialValue(female, "categories", "Princess")
View(femaleAndPrincess)
View(female)
length(femaleAndPrincess)
my.read.csv = function(file.name) {
read.csv(file.name, header = TRUE, encoding = "UTF-8", stringsAsFactors = FALSE)
}
table = my.read.csv("adventuretime.csv")
refactor_names = function(){
names <- readRDS("characterNames.rds")
#exclude unwanted pages:
#Bird_Woman (74) (redirection to Gunter's page)
#Forest_inhabitant (418) (group of characters)
#Son_of_Rap_Bear_(character) (999) (stub)
c = c(74, 418, 999)
names = names[-c]
c1 = which(match(table$name, NA) == 1)
c2 = which(table$name == "{{PAGENAME")
to_ref = sort(c(c1,c2))
newNames = names[to_ref]
table$name[to_ref] = newNames
}
getRowsWithSpecialValue = function(table, colname, value, perfectMatch, dontInvertQuery){
if (missing(perfectMatch)) {
perfectMatch = FALSE
}
if (missing(dontInvertQuery)) {
dontInvertQuery = TRUE
}
if(perfectMatch){
return(table[which(table[colname] == value),])
}
else
return(table[which(grepl(value, table$categories, fixed = T) == dontInvertQuery),])
}
princesses = getRowsWithSpecialValue(table, "categories", "Princess")
noprincesses = getRowsWithSpecialValue(table, "categories", "Princess", dontInvertQuery = FALSE)
female = getRowsWithSpecialValue(table, "sex", "Female", perfectMatch = TRUE)
femaleAndPrincess = getRowsWithSpecialValue(female, "categories", "Princess")
refactor_names()
refactor_names = function(){
names <- readRDS("characterNames.rds")
#exclude unwanted pages:
#Bird_Woman (74) (redirection to Gunter's page)
#Forest_inhabitant (418) (group of characters)
#Son_of_Rap_Bear_(character) (999) (stub)
c = c(74, 418, 999)
names = names[-c]
c1 = which(match(table$name, NA) == 1)
c2 = which(table$name == "{{PAGENAME")
to_ref = sort(c(c1,c2))
newNames = names[to_ref]
table$name[to_ref] = newNames
write.csv(table, file = "adventuretime.csv")
}
refactor_names()
refactor_names = function(){
names <- readRDS("characterNames.rds")
#exclude unwanted pages:
#Bird_Woman (74) (redirection to Gunter's page)
#Forest_inhabitant (418) (group of characters)
#Son_of_Rap_Bear_(character) (999) (stub)
c = c(74, 418, 999)
names = names[-c]
c1 = which(match(table$name, NA) == 1)
c2 = which(table$name == "{{PAGENAME")
to_ref = sort(c(c1,c2))
newNames = names[to_ref]
table$name[to_ref] = newNames
write.csv(as.data.frame(table), file = "adventuretime.csv")
}
refactor_names()
View(table)
library(dplyr)
library(ggplot2)
data(diamonds, economics_long, mpg, package = "ggplot2")
d = data(diamonds, economics_long, mpg, package = "ggplot2")
d
hchart(table, "scatter", hcaes(x = species, y = sex))
install.packages("highcharter")
library("highcharter")
hchart(table, "scatter", hcaes(x = species, y = sex))
library(plotly)
fig <- plot_ly(midwest, x = ~percollege, color = ~state, type = "box")
fig
fig <- plot_ly(table, x = ~sex, color = ~species, type = "box")
fig
fig <- plot_ly(table, x = ~sex, color = ~species)
fig
fig <- plot_ly(table, x = ~sex, y = ~species)
fig
fig <- plot_ly(data = table, x = ~sex, y = ~species)
fig
levels(table$sex)
df = as.data.frame(table$sex)
View(df)
spec = as.data.frame(table$species)
View(spec)
data = cbind(df, spec)
View(data)
names(data)
names(data) = c("sex", "species")
fig <- plot_ly(data = data, x = ~sex, y = ~species)
fig
fig <- plot_ly(data = data, type = "pie")
fig
fig <- plot_ly(data = data, values = ~species, type = "pie")
fig
fig <- plot_ly(data, values = ~species, type = "pie")
fig
data
fig <- plot_ly(data, values = ~species, type = "pie")
fig
fig <- plot_ly(princesses, values = ~species, type = "pie")
fig
ggplot(princesses)
ggplot(princesses) +
geom_point(mapping = aes(x = species, y = sex))
geom_bar(mapping = aes(x = species))
ggplot(princesses) +
geom_bar(mapping = aes(x = species))
ggplot(princesses) +
geom_bar(mapping = aes(x = species)) + coord_flip()
geom_bar(mapping = aes(x = species, color = sex)) + coord_flip()
ggplot(princesses) +
geom_bar(mapping = aes(x = species, color = sex)) + coord_flip()
ggplot(princesses) +
geom_bar(mapping = aes(x = species, fill = sex)) + coord_flip()
ggplot(princesses) +
ggplot(femaleAndprincesses) +
geom_bar(mapping = aes(x = species)) + coord_flip()
ggplot(femaleAndPrincess) +
geom_bar(mapping = aes(x = species)) + coord_flip()
ggplot(data) +
geom_bar(mapping = aes(x = species)) + coord_flip()
